{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79dfc96a",
   "metadata": {},
   "source": [
    "# Step 2 — Data Cleaning (SHP, Cross-Section)\n",
    "\n",
    "This notebook loads the Step-1 dataset (`analysis_dataset_step1.csv`), applies the agreed cleaning rules, and exports a cleaned dataset (`analysis_dataset_step2.csv`).\n",
    "\n",
    "**Key actions**\n",
    "- Drop variables with 100% missing values  \n",
    "- Drop selected variables with high missingness / low relevance  \n",
    "- Restrict sample to adults (age ≥ 18)  \n",
    "- Keep an explicit set of analysis variables  \n",
    "- Export cleaned CSV  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bab405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 120)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e72ce5",
   "metadata": {},
   "source": [
    "## 1) Load Step-1 dataset\n",
    "\n",
    "If your CSV is in the same folder as this notebook, you can keep the default path.\n",
    "Otherwise, adjust `DATA_PATH`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437e5b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"analysis_dataset_step1.csv\"  # adjust if needed\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"Initial shape:\", df.shape)\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08eb6458",
   "metadata": {},
   "source": [
    "## 2) Drop variables with 100% missing values\n",
    "\n",
    "These variables had *no valid observations* in the Step-1 export.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0512c8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_drop_all_missing = [\n",
    "    \"p17a01\",\n",
    "    \"p17c01\",\n",
    "    \"occupa17\",\n",
    "    \"sex17\",\n",
    "]\n",
    "\n",
    "df = df.drop(columns=vars_drop_all_missing, errors=\"ignore\")\n",
    "\n",
    "print(\"After dropping 100% missing variables:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e748c791",
   "metadata": {},
   "source": [
    "## 3) Drop selected variables with high missingness / low analytical relevance\n",
    "\n",
    "Based on the earlier decision, we remove these to improve stability and interpretability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320a5b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_drop_partial_missing = [\n",
    "    \"p17a04\",\n",
    "    \"p17c02\",\n",
    "    \"p17c08\",\n",
    "]\n",
    "\n",
    "df = df.drop(columns=vars_drop_partial_missing, errors=\"ignore\")\n",
    "\n",
    "print(\"After dropping variables with high missings:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac837fd7",
   "metadata": {},
   "source": [
    "## 4) Sample restriction: adults only (age ≥ 18)\n",
    "\n",
    "This defines a clear analytical population for a cross-sectional analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb19702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only adults\n",
    "df = df[df[\"age17\"] >= 18].copy()\n",
    "\n",
    "print(\"After age restriction (18+):\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824c86d0",
   "metadata": {},
   "source": [
    "## 5) Keep an explicit set of analysis variables\n",
    "\n",
    "This ensures a clean, well-defined dataset for Step 3 (recoding + descriptives + regressions).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cc5ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_keep = [\n",
    "    \"idpers\",\n",
    "    \"idhous17\",\n",
    "    \"age17\",\n",
    "    \"nationality17\",\n",
    "    \"edyear17\",\n",
    "    \"isced17\",\n",
    "    \"income17\",\n",
    "    \"nbpers17\",\n",
    "    \"nbkid17\",\n",
    "    \"sport17\",\n",
    "    \"health17\",\n",
    "    \"x17i04\",\n",
    "]\n",
    "\n",
    "# Keep only columns that exist (safe if you rerun with slightly different Step-1 versions)\n",
    "vars_keep_existing = [c for c in vars_keep if c in df.columns]\n",
    "missing_cols = sorted(set(vars_keep) - set(vars_keep_existing))\n",
    "\n",
    "df_step2 = df[vars_keep_existing].copy()\n",
    "\n",
    "print(\"Final dataset shape:\", df_step2.shape)\n",
    "if missing_cols:\n",
    "    print(\"WARNING: These expected columns were not found and were skipped:\", missing_cols)\n",
    "\n",
    "df_step2.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b892d9bb",
   "metadata": {},
   "source": [
    "## 6) Missing-value overview (optional but recommended)\n",
    "\n",
    "Shows the fraction of missing values per variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ccf0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_share = df_step2.isnull().mean().sort_values(ascending=False)\n",
    "display(missing_share)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244b4f8f",
   "metadata": {},
   "source": [
    "## 7) Export cleaned dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d1e91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = \"analysis_dataset_step2.csv\"\n",
    "df_step2.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "print(f\"✅ Cleaned dataset saved as: {OUTPUT_PATH}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
