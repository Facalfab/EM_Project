{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00769bac",
   "metadata": {},
   "source": [
    "# Step 1 — Data Preparation (SHP Main Study) — Waves 2019–2023 (W21–W25)\n",
    "\n",
    "This notebook builds an **analysis-ready long panel dataset** for **2019–2023** from:\n",
    "\n",
    "- Individual (person) files (`*_p_user.dta`)\n",
    "- Household files (`*_h_user.dta`)\n",
    "- **Imputed personal income** (`imputed_income_pers_long_shp.dta`)\n",
    "\n",
    "It will:\n",
    "1. Load each wave folder (`data/raw/W21_2019` … `W25_2023`)\n",
    "2. Merge person + household for each year\n",
    "3. Harmonize key variables across waves using **robust heuristics** (SHP names differ by wave)\n",
    "4. Merge imputed income (person-level) by `idpers` + `year` (or closest matching key)\n",
    "5. Export: `analysis_dataset_step1_panel_2019_2023.csv`\n",
    "\n",
    "> If you prefer a pooled cross-section, you can still use the output and treat it as pooled data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dec502ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/python/3.12.1/lib/python3.12/site-packages (25.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /usr/local/python/3.12.1/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in /usr/local/python/3.12.1/lib/python3.12/site-packages (2.4.0)\n",
      "Requirement already satisfied: pyreadstat in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: narwhals>=2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pyreadstat) (2.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install pandas numpy pyreadstat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07719c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /workspaces/EM_Project\n",
      "RAW_ROOT exists: True -> /workspaces/EM_Project/data/raw\n",
      "WAVES_ROOT detected: /workspaces/EM_Project/data/raw/SHP-Data-W1-W25-STATA\n",
      "Income file detected: /workspaces/EM_Project/data/raw/SHP-Data-Imputed-Income-Wealth-STATA/imputed_income_pers_long_shp.dta\n",
      "Wave folders present: ['W21_2019', 'W22_2020', 'W23_2021', 'W24_2022', 'W25_2023']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# CONFIG (auto-detect SHP folders inside data/raw)\n",
    "# -------------------------------------------------------------------\n",
    "PROJECT_ROOT = os.getcwd()\n",
    "RAW_ROOT = os.path.join(PROJECT_ROOT, \"data\", \"raw\")\n",
    "\n",
    "# Main wave folder (contains W21_2019 ... W25_2023)\n",
    "WAVES_ROOT = None\n",
    "if os.path.isdir(RAW_ROOT):\n",
    "    # common exact folder name\n",
    "    p = os.path.join(RAW_ROOT, \"SHP-Data-W1-W25-STATA\")\n",
    "    if os.path.isdir(p):\n",
    "        WAVES_ROOT = p\n",
    "    else:\n",
    "        # fallback: search one level deep\n",
    "        for entry in os.listdir(RAW_ROOT):\n",
    "            cand = os.path.join(RAW_ROOT, entry)\n",
    "            if os.path.isdir(cand) and re.search(r\"W1[-_]?W25\", entry, flags=re.IGNORECASE):\n",
    "                WAVES_ROOT = cand\n",
    "                break\n",
    "\n",
    "# Income file (imputed income)\n",
    "INCOME_FILE = None\n",
    "if os.path.isdir(RAW_ROOT):\n",
    "    for root, dirs, files in os.walk(RAW_ROOT):\n",
    "        for f in files:\n",
    "            if f.lower() == \"imputed_income_pers_long_shp.dta\":\n",
    "                INCOME_FILE = os.path.join(root, f)\n",
    "                break\n",
    "        if INCOME_FILE:\n",
    "            break\n",
    "\n",
    "WAVE_FOLDERS = [\"W21_2019\", \"W22_2020\", \"W23_2021\", \"W24_2022\", \"W25_2023\"]\n",
    "\n",
    "print(\"Working directory:\", PROJECT_ROOT)\n",
    "print(\"RAW_ROOT exists:\", os.path.isdir(RAW_ROOT), \"->\", RAW_ROOT)\n",
    "print(\"WAVES_ROOT detected:\", WAVES_ROOT)\n",
    "print(\"Income file detected:\", INCOME_FILE)\n",
    "\n",
    "if WAVES_ROOT:\n",
    "    print(\"Wave folders present:\", [wf for wf in WAVE_FOLDERS if os.path.isdir(os.path.join(WAVES_ROOT, wf))])\n",
    "else:\n",
    "    print(\"Wave folders present: []\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e21d2a1",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f48e8681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_file(folder: str, pattern: str) -> str:\n",
    "    for f in os.listdir(folder):\n",
    "        if re.search(pattern, f, flags=re.IGNORECASE):\n",
    "            return os.path.join(folder, f)\n",
    "    raise FileNotFoundError(f\"No file matching {pattern} found in {folder}\")\n",
    "\n",
    "def safe_to_numeric(s):\n",
    "    return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "def pick_first_existing(df, candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def pick_by_regex(df, patterns):\n",
    "    cols = list(df.columns)\n",
    "    for pat in patterns:\n",
    "        rx = re.compile(pat, flags=re.IGNORECASE)\n",
    "        hits = [c for c in cols if rx.search(c)]\n",
    "        if hits:\n",
    "            return hits[0]\n",
    "    return None\n",
    "\n",
    "def wave_num_from_folder(folder_name: str) -> int:\n",
    "    m = re.match(r\"W(\\d{1,2})_\", folder_name)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def year_from_folder(folder_name: str) -> int:\n",
    "    m = re.match(r\"W\\d{1,2}_(\\d{4})\", folder_name)\n",
    "    return int(m.group(1)) if m else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1818a04",
   "metadata": {},
   "source": [
    "## 2) Load & merge each wave (P + H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d8ccd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "Loading W21_2019 | wave=21, year=2019\n",
      "P: shp19_p_user.dta\n",
      "H: shp19_h_user.dta\n",
      "\n",
      "==========================================================================================\n",
      "Loading W22_2020 | wave=22, year=2020\n",
      "P: shp20_p_user.dta\n",
      "H: shp20_h_user.dta\n",
      "\n",
      "==========================================================================================\n",
      "Loading W23_2021 | wave=23, year=2021\n",
      "P: shp21_p_user.dta\n",
      "H: shp21_h_user.dta\n",
      "\n",
      "==========================================================================================\n",
      "Loading W24_2022 | wave=24, year=2022\n",
      "P: shp22_p_user.dta\n",
      "H: shp22_h_user.dta\n",
      "\n",
      "==========================================================================================\n",
      "Loading W25_2023 | wave=25, year=2023\n",
      "P: shp23_p_user.dta\n",
      "H: shp23_h_user.dta\n",
      "\n",
      "Long panel shape: (90910, 3420)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idpers</th>\n",
       "      <th>idhous</th>\n",
       "      <th>year</th>\n",
       "      <th>wave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5101</td>\n",
       "      <td>51</td>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5103</td>\n",
       "      <td>52</td>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5104</td>\n",
       "      <td>51</td>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5201</td>\n",
       "      <td>52</td>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13101</td>\n",
       "      <td>131</td>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idpers  idhous  year  wave\n",
       "0    5101      51  2019    21\n",
       "1    5103      52  2019    21\n",
       "2    5104      51  2019    21\n",
       "3    5201      52  2019    21\n",
       "4   13101     131  2019    21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "panel_parts = []\n",
    "\n",
    "for wf in WAVE_FOLDERS:\n",
    "    folder = os.path.join(WAVES_ROOT, wf)\n",
    "    if not os.path.isdir(folder):\n",
    "        raise FileNotFoundError(f\"Wave folder not found: {folder}. Check WAVES_ROOT and that W21_2019..W25_2023 exist.\")\n",
    "\n",
    "    wave = wave_num_from_folder(wf)\n",
    "    year = year_from_folder(wf)\n",
    "\n",
    "    p_path = find_file(folder, r\"_p_.*user.*\\.dta$\")\n",
    "    h_path = find_file(folder, r\"_h_.*user.*\\.dta$\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(f\"Loading {wf} | wave={wave}, year={year}\")\n",
    "    print(\"P:\", os.path.basename(p_path))\n",
    "    print(\"H:\", os.path.basename(h_path))\n",
    "\n",
    "    df_p = pd.read_stata(p_path, convert_categoricals=False)\n",
    "    df_h = pd.read_stata(h_path, convert_categoricals=False)\n",
    "\n",
    "    if \"idpers\" not in df_p.columns:\n",
    "        raise KeyError(\"idpers not found in person file\")\n",
    "\n",
    "    # Try household id variants\n",
    "    idhous_p = pick_first_existing(df_p, [\"idhous\", f\"idhous{wave:02d}\", f\"idhous{wave}\", f\"idhous{str(year)[-2:]}\"])\n",
    "    idhous_h = pick_first_existing(df_h, [\"idhous\", f\"idhous{wave:02d}\", f\"idhous{wave}\", f\"idhous{str(year)[-2:]}\"])\n",
    "    if idhous_p is None:\n",
    "        idhous_p = pick_by_regex(df_p, [r\"^idhous\"])\n",
    "    if idhous_h is None:\n",
    "        idhous_h = pick_by_regex(df_h, [r\"^idhous\"])\n",
    "    if idhous_p is None or idhous_h is None:\n",
    "        raise KeyError(\"No household id column found for merge (idhous*)\")\n",
    "\n",
    "    df = df_p.merge(df_h, left_on=idhous_p, right_on=idhous_h, how=\"left\", suffixes=(\"\", \"_h\"))\n",
    "    df[\"year\"] = year\n",
    "    df[\"wave\"] = wave\n",
    "    df[\"idpers\"] = df[\"idpers\"]\n",
    "    df[\"idhous\"] = df[idhous_p]\n",
    "\n",
    "    panel_parts.append(df)\n",
    "\n",
    "df_long = pd.concat(panel_parts, ignore_index=True)\n",
    "print(\"\\nLong panel shape:\", df_long.shape)\n",
    "display(df_long[[\"idpers\",\"idhous\",\"year\",\"wave\"]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e056432",
   "metadata": {},
   "source": [
    "## 3) Harmonize core variables (best-effort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe02c41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FAST harmonization took 0.0 seconds\n",
      "Missing share:\n",
      "age           0.0\n",
      "sex           0.0\n",
      "edyear        0.0\n",
      "isced         0.0\n",
      "sport_raw     0.0\n",
      "health_raw    0.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idpers</th>\n",
       "      <th>idhous</th>\n",
       "      <th>year</th>\n",
       "      <th>wave</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>edyear</th>\n",
       "      <th>isced</th>\n",
       "      <th>sport_raw</th>\n",
       "      <th>health_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5101</td>\n",
       "      <td>51</td>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5103</td>\n",
       "      <td>52</td>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5104</td>\n",
       "      <td>51</td>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5201</td>\n",
       "      <td>52</td>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13101</td>\n",
       "      <td>131</td>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13102</td>\n",
       "      <td>131</td>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13103</td>\n",
       "      <td>131</td>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13104</td>\n",
       "      <td>131</td>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21101</td>\n",
       "      <td>211</td>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27101</td>\n",
       "      <td>271</td>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idpers  idhous  year  wave   age  sex  edyear  isced  sport_raw  health_raw\n",
       "0    5101      51  2019    21  58.0  1.0    19.0   51.0        2.0         2.0\n",
       "1    5103      52  2019    21  27.0  1.0     9.0   20.0       -3.0        -3.0\n",
       "2    5104      51  2019    21  58.0  2.0    12.0   32.0       -3.0        -3.0\n",
       "3    5201      52  2019    21  25.0  2.0    12.0   32.0       -3.0        -3.0\n",
       "4   13101     131  2019    21  47.0  1.0    12.0   32.0       -3.0        -3.0\n",
       "5   13102     131  2019    21  46.0  2.0    12.0   32.0        2.0         2.0\n",
       "6   13103     131  2019    21  11.0  2.0     5.0   10.0       -3.0        -3.0\n",
       "7   13104     131  2019    21   9.0  1.0     2.0   10.0       -3.0        -3.0\n",
       "8   21101     211  2019    21  60.0  2.0    12.0   32.0        7.0         2.0\n",
       "9   27101     271  2019    21  51.0  2.0     9.0   20.0        3.0         3.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# NUR benötigte Spalten ziehen (schnell + RAM-schonend)\n",
    "need = [\n",
    "    \"idpers\",\"idhous\",\"year\",\"wave\",\n",
    "    \"age19\",\"age20\",\"age21\",\"age22\",\"age23\",\n",
    "    \"sex19\",\"sex20\",\"sex21\",\"sex22\",\"sex23\",\n",
    "    \"edyear19\",\"edyear20\",\"edyear21\",\"edyear22\",\"edyear23\",\n",
    "    \"isced19\",\"isced20\",\"isced21\",\"isced22\",\"isced23\",\n",
    "    \"p19a04\",\"p20a04\",\"p21a04\",\"p22a04\",\"p23a04\",\n",
    "    \"p19c01\",\"p20c01\",\"p21c01\",\"p22c01\",\"p23c01\",\n",
    "]\n",
    "need = [c for c in need if c in df_long.columns]\n",
    "\n",
    "df_tmp = df_long[need].copy()\n",
    "\n",
    "# Sicherstellen: wave ist 1D numeric\n",
    "wave = pd.to_numeric(df_tmp[\"wave\"], errors=\"coerce\").to_numpy()\n",
    "\n",
    "df_long2 = df_tmp[[\"idpers\",\"idhous\",\"year\",\"wave\"]].copy()\n",
    "\n",
    "# Helper: pick the right column by wave using np.where cascade\n",
    "def by_wave(col19, col20, col21, col22, col23):\n",
    "    arr = np.full(len(df_tmp), np.nan, dtype=\"float64\")\n",
    "    if col19 in df_tmp: arr = np.where(wave == 21, pd.to_numeric(df_tmp[col19], errors=\"coerce\"), arr)\n",
    "    if col20 in df_tmp: arr = np.where(wave == 22, pd.to_numeric(df_tmp[col20], errors=\"coerce\"), arr)\n",
    "    if col21 in df_tmp: arr = np.where(wave == 23, pd.to_numeric(df_tmp[col21], errors=\"coerce\"), arr)\n",
    "    if col22 in df_tmp: arr = np.where(wave == 24, pd.to_numeric(df_tmp[col22], errors=\"coerce\"), arr)\n",
    "    if col23 in df_tmp: arr = np.where(wave == 25, pd.to_numeric(df_tmp[col23], errors=\"coerce\"), arr)\n",
    "    return arr\n",
    "\n",
    "df_long2[\"age\"]        = by_wave(\"age19\",\"age20\",\"age21\",\"age22\",\"age23\")\n",
    "df_long2[\"sex\"]        = by_wave(\"sex19\",\"sex20\",\"sex21\",\"sex22\",\"sex23\")\n",
    "df_long2[\"edyear\"]     = by_wave(\"edyear19\",\"edyear20\",\"edyear21\",\"edyear22\",\"edyear23\")\n",
    "df_long2[\"isced\"]      = by_wave(\"isced19\",\"isced20\",\"isced21\",\"isced22\",\"isced23\")\n",
    "df_long2[\"sport_raw\"]  = by_wave(\"p19a04\",\"p20a04\",\"p21a04\",\"p22a04\",\"p23a04\")\n",
    "df_long2[\"health_raw\"] = by_wave(\"p19c01\",\"p20c01\",\"p21c01\",\"p22c01\",\"p23c01\")\n",
    "\n",
    "print(\"✅ FAST harmonization took\", round(time.time() - t0, 1), \"seconds\")\n",
    "\n",
    "print(\"Missing share:\")\n",
    "print(df_long2[[\"age\",\"sex\",\"edyear\",\"isced\",\"sport_raw\",\"health_raw\"]].isna().mean().sort_values())\n",
    "\n",
    "df_long2.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "805e4842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing share after recode:\n",
      "sex           0.000044\n",
      "age           0.000737\n",
      "isced         0.012111\n",
      "edyear        0.012683\n",
      "health_raw    0.342548\n",
      "sport_raw     0.488186\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# typische SHP missing codes (kann je nach Modul leicht variieren)\n",
    "missing_codes = [-1, -2, -3, -4, -5, -6, -7, -8, -9]\n",
    "\n",
    "cols_to_clean = [\"sport_raw\", \"health_raw\", \"age\", \"sex\", \"edyear\", \"isced\"]\n",
    "for c in cols_to_clean:\n",
    "    df_long2[c] = df_long2[c].replace(missing_codes, np.nan)\n",
    "\n",
    "print(\"Missing share after recode:\")\n",
    "print(df_long2[cols_to_clean].isna().mean().sort_values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f3afdf",
   "metadata": {},
   "source": [
    "## 4) Merge imputed personal income (2019–2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff5a3ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Income file shape: (216412, 55) | read_stata took 0.1 s\n",
      "Detected income time key: year\n",
      "Income filtered shape (2019–2023): (59911, 55) | filter+copy took 0.0 s\n",
      "Income label hits (usable): ['iptotni', 'iempyni', 'iindyni', 'ioasiyi', 'ipenyi', 'iuneyi', 'iwelyi', 'iinsyi', 'ipihyi', 'ipnhyi'] … total: 36\n",
      "Chosen income variable: iptotni\n",
      "df_core shape: (90910, 10) | core extract took 0.0 s\n",
      "After income merge: (90910, 11) | merge took 0.0 s\n",
      "Head (income):\n",
      "   idpers  year  income_imputed\n",
      "0    5101  2019        117000.0\n",
      "1    5103  2019             NaN\n",
      "2    5104  2019             NaN\n",
      "3    5201  2019             NaN\n",
      "4   13101  2019             NaN\n",
      "5   13102  2019         40400.0\n",
      "6   13103  2019             NaN\n",
      "7   13104  2019             NaN\n",
      "8   21101  2019         27600.0\n",
      "9   27101  2019          8500.0\n",
      "TOTAL income block took 2.1 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "t0_all = time.time()\n",
    "\n",
    "if INCOME_FILE is None:\n",
    "    raise FileNotFoundError(\"imputed_income_pers_long_shp.dta not found under data/raw\")\n",
    "\n",
    "# Load income file\n",
    "t0 = time.time()\n",
    "income = pd.read_stata(INCOME_FILE, convert_categoricals=False)\n",
    "print(\"Income file shape:\", income.shape, \"| read_stata took\", round(time.time() - t0, 1), \"s\")\n",
    "\n",
    "if \"idpers\" not in income.columns:\n",
    "    raise KeyError(\"Income file does not contain 'idpers'.\")\n",
    "\n",
    "# Detect time key\n",
    "time_key = None\n",
    "for cand in [\"year\", \"yr\", \"syear\", \"survey_year\", \"wave\"]:\n",
    "    if cand in income.columns:\n",
    "        time_key = cand\n",
    "        break\n",
    "if time_key is None:\n",
    "    time_key = pick_by_regex(income, [r\"^year$\", r\"^wave$\", r\".*year.*\"])\n",
    "\n",
    "print(\"Detected income time key:\", time_key)\n",
    "if time_key is None:\n",
    "    raise KeyError(\"Could not detect a time key in income file.\")\n",
    "\n",
    "# Build year series (without copying entire df first)\n",
    "if str(time_key).lower() == \"wave\":\n",
    "    wave_to_year = {21: 2019, 22: 2020, 23: 2021, 24: 2022, 25: 2023}\n",
    "    year_series = pd.to_numeric(income[time_key], errors=\"coerce\").map(wave_to_year)\n",
    "else:\n",
    "    year_series = pd.to_numeric(income[time_key], errors=\"coerce\")\n",
    "\n",
    "mask = year_series.between(2019, 2023, inclusive=\"both\")\n",
    "\n",
    "t0 = time.time()\n",
    "income2 = income.loc[mask, :].copy()\n",
    "income2[\"year\"] = year_series.loc[mask].values\n",
    "print(\"Income filtered shape (2019–2023):\", income2.shape, \"| filter+copy took\", round(time.time() - t0, 1), \"s\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Choose correct income variable (labels first)\n",
    "# ------------------------------------------------------------\n",
    "income_var = None\n",
    "try:\n",
    "    import pyreadstat\n",
    "    _, meta = pyreadstat.read_dta(INCOME_FILE)\n",
    "\n",
    "    keywords = [\"income\", \"earn\", \"wage\", \"salary\", \"labour\", \"labor\", \"gross\", \"net\", \"disposable\"]\n",
    "\n",
    "    label_hits = []\n",
    "    for name, label in zip(meta.column_names, meta.column_labels):\n",
    "        lab = (label or \"\").lower()\n",
    "        if any(k in lab for k in keywords):\n",
    "            label_hits.append(name)\n",
    "\n",
    "    exclude = re.compile(r\"^(id|idh|filter|wgt|weight|year|wave)\", re.IGNORECASE)\n",
    "    label_hits = [c for c in label_hits if c in income2.columns]\n",
    "    label_hits = [c for c in label_hits if (c in income2.select_dtypes(include=[np.number]).columns) and not exclude.search(c)]\n",
    "\n",
    "    if label_hits:\n",
    "        income_var = label_hits[0]\n",
    "\n",
    "    print(\"Income label hits (usable):\", label_hits[:10], \"… total:\", len(label_hits))\n",
    "except Exception as e:\n",
    "    print(\"pyreadstat label search skipped/failed:\", repr(e))\n",
    "\n",
    "# Fallback if labels don't work\n",
    "if income_var is None:\n",
    "    num_cols = income2.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    exclude = re.compile(r\"^(id|idh|filter|wgt|weight|year|wave)\", re.IGNORECASE)\n",
    "    candidates = [c for c in num_cols if not exclude.search(c)]\n",
    "\n",
    "    name_like = [c for c in candidates if re.search(r\"inc|income|earn|wage|salary|gross|net|hhinc\", c, flags=re.IGNORECASE)]\n",
    "    if name_like:\n",
    "        income_var = name_like[0]\n",
    "    else:\n",
    "        best, best_score = None, -1\n",
    "        for c in candidates:\n",
    "            s = pd.to_numeric(income2[c], errors=\"coerce\")\n",
    "            nonmiss = s.notna().mean()\n",
    "            if nonmiss < 0.20:\n",
    "                continue\n",
    "            std = s.std(skipna=True)\n",
    "            pos_share = (s.dropna() > 0).mean() if s.notna().any() else 0\n",
    "            uniq = s.nunique(dropna=True)\n",
    "            if uniq <= 5 and std < 5:\n",
    "                continue\n",
    "            score = nonmiss * 1.0 + np.log1p(std) * 0.8 + pos_share * 0.5 + (np.log1p(uniq) / 10)\n",
    "            if score > best_score:\n",
    "                best_score, best = score, c\n",
    "        income_var = best\n",
    "\n",
    "print(\"Chosen income variable:\", income_var)\n",
    "if income_var is None:\n",
    "    raise ValueError(\"Could not select an income variable. Please inspect income2 columns/labels.\")\n",
    "\n",
    "# Keep only needed columns for merge\n",
    "income_keep = income2[[\"idpers\", \"year\", income_var]].copy()\n",
    "income_keep = income_keep.rename(columns={income_var: \"income_imputed\"})\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# IMPORTANT SPEED FIX: reduce df_long2 before merge (3420 cols -> ~10 cols)\n",
    "# ------------------------------------------------------------\n",
    "t0 = time.time()\n",
    "core_cols = [\"idpers\", \"idhous\", \"year\", \"wave\", \"age\", \"sex\", \"edyear\", \"isced\", \"sport_raw\", \"health_raw\"]\n",
    "core_cols = [c for c in core_cols if c in df_long2.columns]\n",
    "df_core = df_long2[core_cols].copy()\n",
    "print(\"df_core shape:\", df_core.shape, \"| core extract took\", round(time.time() - t0, 1), \"s\")\n",
    "\n",
    "# Merge to panel (fast now)\n",
    "t0 = time.time()\n",
    "df_panel = df_core.merge(income_keep, on=[\"idpers\", \"year\"], how=\"left\")\n",
    "print(\"After income merge:\", df_panel.shape, \"| merge took\", round(time.time() - t0, 1), \"s\")\n",
    "\n",
    "print(\"Head (income):\")\n",
    "print(df_panel[[\"idpers\", \"year\", \"income_imputed\"]].head(10))\n",
    "\n",
    "print(\"TOTAL income block took\", round(time.time() - t0_all, 1), \"s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc1bd1d",
   "metadata": {},
   "source": [
    "## 5) Build minimal analysis dataset and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bfc0882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export dataset shape: (90910, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idpers</th>\n",
       "      <th>idhous</th>\n",
       "      <th>year</th>\n",
       "      <th>wave</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>edyear</th>\n",
       "      <th>isced</th>\n",
       "      <th>sport_raw</th>\n",
       "      <th>health_raw</th>\n",
       "      <th>income_imputed</th>\n",
       "      <th>nbpers</th>\n",
       "      <th>nbkid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5101</td>\n",
       "      <td>51</td>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>117000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5103</td>\n",
       "      <td>52</td>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5104</td>\n",
       "      <td>51</td>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5201</td>\n",
       "      <td>52</td>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13101</td>\n",
       "      <td>131</td>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idpers  idhous  year  wave   age  sex  edyear  isced  sport_raw  health_raw  income_imputed  nbpers  nbkid\n",
       "0    5101      51  2019    21  58.0  1.0    19.0   51.0        2.0         2.0        117000.0     NaN    NaN\n",
       "1    5103      52  2019    21  27.0  1.0     9.0   20.0        NaN         NaN             NaN     NaN    NaN\n",
       "2    5104      51  2019    21  58.0  2.0    12.0   32.0        NaN         NaN             NaN     NaN    NaN\n",
       "3    5201      52  2019    21  25.0  2.0    12.0   32.0        NaN         NaN             NaN     NaN    NaN\n",
       "4   13101     131  2019    21  47.0  1.0    12.0   32.0        NaN         NaN             NaN     NaN    NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: analysis_dataset_step1_panel_2019_2023.csv\n"
     ]
    }
   ],
   "source": [
    "# household structure best-effort\n",
    "nbpers_col = pick_by_regex(df_panel, [r\"^nbpers\\d{2}$\", r\"^nbpers$\"])\n",
    "nbkid_col  = pick_by_regex(df_panel, [r\"^nbkid\\d{2}$\", r\"^nbkid$\"])\n",
    "\n",
    "df_panel[\"nbpers\"] = safe_to_numeric(df_panel[nbpers_col]) if nbpers_col else np.nan\n",
    "df_panel[\"nbkid\"]  = safe_to_numeric(df_panel[nbkid_col]) if nbkid_col else np.nan\n",
    "\n",
    "vars_keep = [\n",
    "    \"idpers\",\"idhous\",\"year\",\"wave\",\n",
    "    \"age\",\"sex\",\"edyear\",\"isced\",\n",
    "    \"sport_raw\",\"health_raw\",\"income_imputed\",\n",
    "    \"nbpers\",\"nbkid\",\n",
    "]\n",
    "\n",
    "df_out = df_panel[vars_keep].copy()\n",
    "print(\"Export dataset shape:\", df_out.shape)\n",
    "display(df_out.head())\n",
    "\n",
    "OUTPUT_PATH = \"analysis_dataset_step1_panel_2019_2023.csv\"\n",
    "df_out.to_csv(OUTPUT_PATH, index=False)\n",
    "print(\"✅ Saved:\", OUTPUT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69fcb97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^age -> ['age19', 'age20', 'age21', 'age22', 'age23']\n",
      "^sex -> ['sex19', 'sex20', 'sex21', 'sex22', 'sex23']\n",
      "^edyear -> ['edyear19', 'edyear20', 'edyear21', 'edyear22', 'edyear23']\n",
      "^isced -> ['isced19', 'isced20', 'isced21', 'isced22', 'isced23']\n",
      "^p19a -> ['p19a01', 'p19a04', 'p19a05', 'p19a06', 'p19a14', 'p19a08', 'p19a10', 'p19a11', 'p19a13', 'p19a17', 'p19a19', 'p19a09', 'p19a09a', 'p19a09b', 'p19a09c', 'p19a09d', 'p19a120', 'p19a15', 'p19a18a', 'p19a18b']\n",
      "^p19c -> ['p19c44', 'p19c47', 'p19c48', 'p19c49', 'p19c50', 'p19c01', 'p19c02', 'p19c03', 'p19c04a', 'p19c05a', 'p19c06a', 'p19c07a', 'p19c08', 'p19c19a', 'p19c11', 'p19c12', 'p19c15', 'p19c186', 'p19c191', 'p19c193']\n",
      "^p20a -> ['p20a01', 'p20a04', 'p20a05', 'p20a06']\n",
      "^p20c -> ['p20c44', 'p20c47', 'p20c48', 'p20c49', 'p20c50', 'p20c01', 'p20c02', 'p20c03', 'p20c04a', 'p20c05a', 'p20c06a', 'p20c07a', 'p20c08', 'p20c19a', 'p20c11', 'p20c12', 'p20c15', 'p20c186', 'p20c191', 'p20c193']\n",
      "^p21a -> ['p21a01', 'p21a04', 'p21a05', 'p21a06']\n",
      "^p21c -> ['p21c44', 'p21c100', 'p21c101', 'p21c102', 'p21c103', 'p21c47', 'p21c48', 'p21c49', 'p21c50', 'p21c01', 'p21c02', 'p21c03', 'p21c04a', 'p21c05a', 'p21c06a', 'p21c07a', 'p21c08', 'p21c19a', 'p21c21a', 'p21c195']\n",
      "^p22a -> ['p22a01', 'p22a04', 'p22a05', 'p22a06', 'p22a14', 'p22a08', 'p22a10', 'p22a11', 'p22a13', 'p22a17', 'p22a19', 'p22a09', 'p22a120', 'p22a15', 'p22a18a', 'p22a18b', 'p22a121', 'p22a122', 'p22a123', 'p22a124']\n",
      "^p22c -> ['p22c44', 'p22c47', 'p22c48', 'p22c49', 'p22c50', 'p22c01', 'p22c02', 'p22c03', 'p22c04a', 'p22c05a', 'p22c06a', 'p22c07a', 'p22c08', 'p22c19a', 'p22c21a', 'p22c195', 'p22c196', 'p22c197', 'p22c198', 'p22c199']\n",
      "^p23a -> ['p23a01', 'p23a04', 'p23a05', 'p23a06']\n",
      "^p23c -> ['p23c44', 'p23c47', 'p23c48', 'p23c49', 'p23c50', 'p23c01', 'p23c02', 'p23c03', 'p23c04a', 'p23c05a', 'p23c06a', 'p23c07a', 'p23c08', 'p23c19a', 'p23c21a', 'p23c195', 'p23c196', 'p23c197', 'p23c198', 'p23c199']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "cols = df_long.columns\n",
    "\n",
    "def show(pattern, n=20):\n",
    "    hits = [c for c in cols if re.search(pattern, c)]\n",
    "    print(pattern, \"->\", hits[:n])\n",
    "\n",
    "# Demografie\n",
    "show(r\"^age\")\n",
    "show(r\"^sex\")\n",
    "show(r\"^edyear\")\n",
    "show(r\"^isced\")\n",
    "\n",
    "# Sport & Gesundheit nach Jahr-Suffix (19–23)\n",
    "show(r\"^p19a\")\n",
    "show(r\"^p19c\")\n",
    "show(r\"^p20a\")\n",
    "show(r\"^p20c\")\n",
    "show(r\"^p21a\")\n",
    "show(r\"^p21c\")\n",
    "show(r\"^p22a\")\n",
    "show(r\"^p22c\")\n",
    "show(r\"^p23a\")\n",
    "show(r\"^p23c\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
